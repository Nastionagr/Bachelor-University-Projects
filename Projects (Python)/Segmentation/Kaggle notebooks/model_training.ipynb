{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training of models (Unet and DeepLabV3)\n","Code inspired  by Eugenia Anello. Source : https://github.com/eugeniaring/Medium-Articles/blob/main/Pytorch/denAE.ipynb\n","\n","**The main differences:**\n","* Weights & Biases platform calling implemetation\n","* Unet architecture and usage of DeepLabV3\n","* New dataset class\n","* Change od displaying output\n","* Whole new output processing and more"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# root_path       - path to the wound dataset\n","# csv_path_folder - path to the folder containing csvs with lists of image names used in given dataset (test, train, validate)\n","# model_type      - swith between different model types. Three model types are supported: 'Unet-Sigmoid', 'Unet-ReLU' and 'DeepLabV3'\n","# unet_relu_path  - path to the defined model in .py file. Must be set if given model is being used\n","# unet_sigm_path  - path to the defined model in .py file. Must be set if given model is being used \n","\n","root_path =       '../input/350pics/dataset'\n","csv_path_folder = '../input/wound-dataset-splitedlist/sort whole/'\n","\n","model_type =      'Unet-Sigmoid' # 'Unet-Sigmoid' # 'Unet-ReLU' # 'DeepLabV3'\n","\n","unet_relu_path =  '../input/sigmoid-model/unet_model.py'\n","unet_sigm_path =  '../input/nn-model/unet_model.py'"]},{"cell_type":"markdown","metadata":{},"source":["**INITIALIZATION**"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-05-26T09:33:00.215011Z","iopub.status.busy":"2022-05-26T09:33:00.21458Z","iopub.status.idle":"2022-05-26T09:33:04.167821Z","shell.execute_reply":"2022-05-26T09:33:04.167081Z","shell.execute_reply.started":"2022-05-26T09:33:00.214878Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","from skimage import io\n","import seaborn as sb\n","import pandas as pd\n","import numpy as np\n","import random\n","import wandb\n","import time\n","import csv\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as data\n","from torchvision import transforms#, datasets\n","from torch.utils.data import DataLoader,random_split\n","\n","random.seed(22)\n","torch.random.manual_seed(22)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:04.171527Z","iopub.status.busy":"2022-05-26T09:33:04.171316Z","iopub.status.idle":"2022-05-26T09:33:15.008989Z","shell.execute_reply":"2022-05-26T09:33:15.008157Z","shell.execute_reply.started":"2022-05-26T09:33:04.171498Z"},"trusted":true},"outputs":[],"source":["wandb.login()\n","wandb.init(project=\"wound_image_processing\", entity=\"------\") # insert username"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:15.011181Z","iopub.status.busy":"2022-05-26T09:33:15.010696Z","iopub.status.idle":"2022-05-26T09:33:15.085098Z","shell.execute_reply":"2022-05-26T09:33:15.084334Z","shell.execute_reply.started":"2022-05-26T09:33:15.011137Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(f'Selected device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:15.09323Z","iopub.status.busy":"2022-05-26T09:33:15.090677Z","iopub.status.idle":"2022-05-26T09:33:15.104188Z","shell.execute_reply":"2022-05-26T09:33:15.103393Z","shell.execute_reply.started":"2022-05-26T09:33:15.093183Z"},"trusted":true},"outputs":[],"source":["# Global values and settings for the NN\n","\n","lr= 0.00005 # 0.00001\n","num_epochs = 1000\n","batch_size= 4\n","save_checkpoint = True\n","\n","wandb.config = {\n","    \"learning_rate\": lr,\n","    \"epochs\": num_epochs,\n","    \"batch_size\": batch_size,\n","    \"save_checkpoint\": save_checkpoint\n","}\n","\n","# Marking each class with the color (for example: 0 (granulation) is red color (255, 0, 0) in RGB model)\n","\n","switcher = {\n","        0: [255, 0, 0], # granulation tissue\n","        1: [0, 255, 0], # slough tissue\n","        2: [0, 0, 255], # necrotic tissue\n","        3: [0, 0, 0]    # background\n","    }\n","\n","# Colors for printing some important stuff\n","\n","CSTART = '\\033[41m'\n","CEND = '\\033[0m'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:15.111518Z","iopub.status.busy":"2022-05-26T09:33:15.108808Z","iopub.status.idle":"2022-05-26T09:33:18.384649Z","shell.execute_reply":"2022-05-26T09:33:18.383957Z","shell.execute_reply.started":"2022-05-26T09:33:15.111463Z"},"trusted":true},"outputs":[],"source":["# model = Unet()\n","\n","assert model_type in ('Unet-Sigmoid', 'Unet-ReLU', 'DeepLabV3'), \"model name should be 'Unet-Sigmoid', 'Unet-ReLU' or 'DeepLabV3'\"\n","\n","if model_type.startswith('Unet'):\n","    # Loading model from the python file\n","    from shutil import copyfile\n","    unetpath = unet_relu_path if model_type == 'Unet-Sigmoid' else unet_sigm_path\n","    copyfile(src = unetpath, dst = \"../working/unet_model.py\")\n","    from unet_model import Unet\n","    model = Unet()\n","    \n","elif model_type == 'DeepLabV3':\n","    from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n","    from torchvision import models\n","    model = models.segmentation.deeplabv3_resnet101(pretrained=True, progress=True)\n","    outputchannels=4\n","    model.classifier = DeepLabHead(2048, outputchannels)\n","else:\n","    raise Exception(\"model name should be 'Unet-Sigmoid', 'Unet-ReLU' or 'DeepLabV3'\")\n","    \n","optim = torch.optim.Adam(model.parameters(), lr=lr)\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["**DOWNLOADING WOUND DATASET**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:18.388581Z","iopub.status.busy":"2022-05-26T09:33:18.388315Z","iopub.status.idle":"2022-05-26T09:33:18.405851Z","shell.execute_reply":"2022-05-26T09:33:18.405095Z","shell.execute_reply.started":"2022-05-26T09:33:18.388548Z"},"trusted":true},"outputs":[],"source":["# Creating the class to work with the dataset\n","\n","class WoundDataset(data.Dataset):\n","\n","    def __init__(self, root, transform=None, csv_file=None):\n","        self.img_orig = root + '/imgs'  # folder with the resized images (512 * 512)\n","        self.img_mask = root + '/masks' # folder with the masks to these images\n","        self.transform = transform\n","        \n","        if csv_file is None:\n","            self.imglist = os.listdir(self.img_orig)\n","        else:\n","            with open(csv_file, newline='') as csvfile:\n","                spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n","                csv_img_list = [row[1] for row in spamreader][1:]\n","                self.imglist = [filename for filename in os.listdir(self.img_orig) if filename in csv_img_list]\n","                \n","    def __len__(self):\n","        return len(self.imglist)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_name = os.path.join(self.img_orig, self.imglist[idx])\n","        msk_name = os.path.join(self.img_mask, self.imglist[idx])\n","        \n","        img = io.imread(img_name)\n","        msk = io.imread(msk_name)[:,:,:3] # reading just RGB channels (without hue)\n","        \n","        if self.transform:\n","            img = self.transform(img)\n","            msk = self.transform(msk)\n","\n","        return img, msk"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:18.407485Z","iopub.status.busy":"2022-05-26T09:33:18.407249Z","iopub.status.idle":"2022-05-26T09:33:18.427293Z","shell.execute_reply":"2022-05-26T09:33:18.425038Z","shell.execute_reply.started":"2022-05-26T09:33:18.407455Z"},"trusted":true},"outputs":[],"source":["# Function for coding the input to the NN\n","\n","def convert_into_1d(old_tensor):\n","    # pixels that will be marked as a backgroung\n","    max_pixel_value = (torch.max(torch.flatten(old_tensor))).cpu().numpy()\n","    color_threshold = 0.5 * max_pixel_value\n","    \n","    # 1 - additional channel for the class labeling\n","    new_tensor = torch.full((old_tensor.shape[0], 1, old_tensor.shape[2], old_tensor.shape[3]), color_threshold)\n","    \n","    old_tensor = old_tensor.to(device)\n","    new_tensor = new_tensor.to(device)\n","    \n","    # concatenate two tensors\n","    old_tensor = torch.cat((old_tensor, new_tensor), dim=1)\n","    \n","    # finding the layer with the maximum pixel value\n","    max_idxs = torch.argmax(old_tensor, dim=1)\n","                    \n","    return max_idxs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:18.433978Z","iopub.status.busy":"2022-05-26T09:33:18.430853Z","iopub.status.idle":"2022-05-26T09:33:18.44262Z","shell.execute_reply":"2022-05-26T09:33:18.441877Z","shell.execute_reply.started":"2022-05-26T09:33:18.433938Z"},"trusted":true},"outputs":[],"source":["# Additional function that helps to match an exact class (0-3) with the color (that it is marked in RGB color model)\n","\n","def converting_to_rgb_layers(x):\n","    global switcher\n","    return switcher.get(int(x[0]), \"error\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:18.444382Z","iopub.status.busy":"2022-05-26T09:33:18.444129Z","iopub.status.idle":"2022-05-26T09:33:18.453832Z","shell.execute_reply":"2022-05-26T09:33:18.453147Z","shell.execute_reply.started":"2022-05-26T09:33:18.444347Z"},"trusted":true},"outputs":[],"source":["# Function for decoding final mask (NN output)\n","\n","def convert_into_3d(output_mask):\n","    # create a new 'empty' tensor\n","    zero_tensor = torch.zeros(output_mask.shape[1], output_mask.shape[2], 1)\n","    \n","    # detecting which layer has to be displayed in the picture\n","    dominant_layers = torch.argmax(torch.tensor(output_mask), dim=0).unsqueeze(2)\n","    \n","    # creating a new 3-dimentional tensor\n","    # first dim - dominant layer, other - empty layers\n","    three_dim_tensor = torch.cat((dominant_layers, zero_tensor, zero_tensor), dim=2)\n","    # converting it to numpy array\n","    numpy_array = three_dim_tensor.detach().numpy()\n","        \n","    # changing dominant layers to rgb image\n","    numpy_array = np.apply_along_axis(converting_to_rgb_layers, -1, numpy_array)\n","        \n","    return numpy_array"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:18.458383Z","iopub.status.busy":"2022-05-26T09:33:18.458187Z","iopub.status.idle":"2022-05-26T09:33:18.547895Z","shell.execute_reply":"2022-05-26T09:33:18.547112Z","shell.execute_reply.started":"2022-05-26T09:33:18.458359Z"},"trusted":true},"outputs":[],"source":["# Creating the dataset\n","\n","dataset = WoundDataset(root = root_path, transform = transforms.ToTensor())\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:18.551263Z","iopub.status.busy":"2022-05-26T09:33:18.550802Z","iopub.status.idle":"2022-05-26T09:33:18.573102Z","shell.execute_reply":"2022-05-26T09:33:18.572454Z","shell.execute_reply.started":"2022-05-26T09:33:18.551227Z"},"trusted":true},"outputs":[],"source":["# Creating a function for displaying images with their masks\n","# First 3 images are permanent, the last 3 are changing\n","\n","def display_data(dataset, model=None, n_base=3, n_rand=3):\n","    n = n_base + n_rand\n","    plt.figure(figsize=(25,7))\n","    \n","    for i in range(n):\n","        if(i >= n_base):\n","            index=random.randint(n, len(dataset)-1)\n","        else:\n","            index = i\n"," \n","        ax = plt.subplot(3 if model else 2, n, i+1)\n","        \n","        image, mask = dataset[index]\n","        original_image = image.to(device).unsqueeze(0)\n","        original_mask = mask\n","        \n","        if model:\n","            model.eval()\n","\n","        with torch.no_grad():\n","            image = np.transpose(np.array(image), (1,2,0))\n","            ax = plt.subplot(3 if model else 2, n, i+1)\n","            ax.imshow(image)\n","            ax.get_xaxis().set_visible(False)\n","            ax.get_yaxis().set_visible(False)\n","            if i == n//2:\n","                ax.set_title('Input images')\n","\n","            original_mask = np.transpose(np.array(original_mask), (1,2,0))\n","            ax = plt.subplot(3 if model else 2, n, n+i+1)\n","            ax.imshow(original_mask)\n","            ax.get_xaxis().set_visible(False)\n","            ax.get_yaxis().set_visible(False)  \n","            if i == n//2:\n","                ax.set_title('Original masks')\n","            \n","            if model:\n","                output_mask = model(original_image)\n","                if model_type == 'DeepLabV3':\n","                    output_mask = output_mask['out']\n","                output_mask  = output_mask.squeeze(0).cpu()\n","                output_mask = convert_into_3d(output_mask) # decoding the output\n","                ax = plt.subplot(3, n, 2*n+i+1)\n","                plt.imshow(output_mask)\n","                ax.get_xaxis().set_visible(False)\n","                ax.get_yaxis().set_visible(False)  \n","                if i == n//2:\n","                    ax.set_title('Generated masks')\n","            \n","    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.7, top=0.9, wspace=0.3, hspace=0.3)   \n","    \n","    plt.show()   "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:18.574538Z","iopub.status.busy":"2022-05-26T09:33:18.574196Z","iopub.status.idle":"2022-05-26T09:33:19.980326Z","shell.execute_reply":"2022-05-26T09:33:19.97957Z","shell.execute_reply.started":"2022-05-26T09:33:18.574508Z"},"trusted":true},"outputs":[],"source":["display_data(dataset)"]},{"cell_type":"markdown","metadata":{},"source":["**SPLITTING THE DATASET**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:19.981569Z","iopub.status.busy":"2022-05-26T09:33:19.981342Z","iopub.status.idle":"2022-05-26T09:33:20.0174Z","shell.execute_reply":"2022-05-26T09:33:20.016712Z","shell.execute_reply.started":"2022-05-26T09:33:19.98154Z"},"trusted":true},"outputs":[],"source":["# Dividing the whole dataset\n","# Ratio: 70% - train, 15% - test, 15% - validation\n","\n","train_ratio = 0.7\n","test_ratio = 0.15\n","\n","train_size = int(np.floor(train_ratio * len(dataset)))\n","test_size = int(np.floor(test_ratio * len(dataset)))\n","\n","# CHANGE - NAST - Load from csvs as new datasets\n","# data_train, data_test_val = torch.utils.data.random_split(dataset, [train_size, len(dataset)-train_size])\n","# data_test, data_val = torch.utils.data.random_split(data_test_val, [test_size, len(data_test_val)-test_size])\n","data_train = WoundDataset(root = root_path, transform = transforms.ToTensor(), csv_file=csv_path_folder+'train.csv')\n","data_test =  WoundDataset(root = root_path, transform = transforms.ToTensor(), csv_file=csv_path_folder+'test.csv')\n","data_val =   WoundDataset(root = root_path, transform = transforms.ToTensor(), csv_file=csv_path_folder+'val.csv')\n","\n","train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n","test_loader =  torch.utils.data.DataLoader(data_test, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=2)\n","val_loader =   torch.utils.data.DataLoader(data_val, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{},"source":["**PERFORMING SMALL DATA ANALYSIS**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:20.018876Z","iopub.status.busy":"2022-05-26T09:33:20.018542Z","iopub.status.idle":"2022-05-26T09:33:20.027782Z","shell.execute_reply":"2022-05-26T09:33:20.026893Z","shell.execute_reply.started":"2022-05-26T09:33:20.018839Z"},"trusted":true},"outputs":[],"source":["# Check the size of the dataset\n","\n","size_of_the_dataset = str(len(dataset))\n","print('Whole dataset len: ', size_of_the_dataset)\n","print('Train dataset len: ', len(data_train))\n","print('Test  dataset len: ', len(data_test))\n","print('Val   dataset len: ', len(data_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:20.029737Z","iopub.status.busy":"2022-05-26T09:33:20.029048Z","iopub.status.idle":"2022-05-26T09:33:20.037958Z","shell.execute_reply":"2022-05-26T09:33:20.037071Z","shell.execute_reply.started":"2022-05-26T09:33:20.029702Z"},"trusted":true},"outputs":[],"source":["# Count the ration of each class\n","\n","def count_color_ratio(dataset):\n","    data = []\n","    for index in range(len(dataset)):\n","        image, mask = dataset[index]\n","        \n","        binary_classes = torch.where(mask > 0, 1, 0)\n","        r_total, g_total, b_total = map(int, (torch.sum(binary_classes[i]) for i in range (3)))\n","        black_total = mask.shape[1] * mask.shape[2] - (r_total + g_total + b_total)\n","\n","        data.append((r_total, g_total, b_total, black_total))\n","\n","    return pd.DataFrame(data, columns=['number_of_RED_pixels', 'number_of_GREEN_pixels', 'number_of_BLUE_pixels', 'number_of_BLACK_pixels'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:20.039689Z","iopub.status.busy":"2022-05-26T09:33:20.039153Z","iopub.status.idle":"2022-05-26T09:33:28.543429Z","shell.execute_reply":"2022-05-26T09:33:28.542745Z","shell.execute_reply.started":"2022-05-26T09:33:20.039656Z"},"trusted":true},"outputs":[],"source":["# Show a few counted results\n","\n","df = count_color_ratio(data_train)\n","df.sample(n=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:28.54502Z","iopub.status.busy":"2022-05-26T09:33:28.544756Z","iopub.status.idle":"2022-05-26T09:33:28.656541Z","shell.execute_reply":"2022-05-26T09:33:28.655845Z","shell.execute_reply.started":"2022-05-26T09:33:28.544977Z"},"trusted":true},"outputs":[],"source":["# Displaying the results\n","\n","labels = 'GRANULATION TISSUE (red pixels)', 'SLOUGH TISSUE (green pixels)', 'NECROTIC TISSUE (blue pixels)'\n","red_sum, green_sum, blue_sum = df['number_of_RED_pixels'].sum(), df['number_of_GREEN_pixels'].sum(), df['number_of_BLUE_pixels'].sum()\n","\n","fig, ax = plt.subplots()\n","ax.pie([red_sum, green_sum, blue_sum], labels = labels, autopct = '%1.1f%%', colors = ['#b56576', '#eaac8b', '#6d597a'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Due to the class inequality, future neural network has to use weighted loss function.\n","\n","For a better performance the equal class distribution is required. There are 3 classes of different tissue types, so the ratio is 100/3 ~ 33% for each class."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:28.658285Z","iopub.status.busy":"2022-05-26T09:33:28.657865Z","iopub.status.idle":"2022-05-26T09:33:28.665783Z","shell.execute_reply":"2022-05-26T09:33:28.664852Z","shell.execute_reply.started":"2022-05-26T09:33:28.658248Z"},"trusted":true},"outputs":[],"source":["sum_all = red_sum + green_sum + blue_sum\n","basic_ratio = 33.3\n","red_ratio, green_ratio, blue_ratio, black_ratio = basic_ratio/red_sum/100*sum_all, basic_ratio/green_sum/100*sum_all, basic_ratio/blue_sum/100*sum_all, 1\n","print(\"Red ratio: %.2f\\nGreen ratio: %.2f\\nBlue ratio: %.2f\\n\" % (red_ratio, green_ratio, blue_ratio))"]},{"cell_type":"markdown","metadata":{},"source":["**INITIALIZING UNET NEURAL NETWORK**"]},{"cell_type":"markdown","metadata":{},"source":["Choosing loss function:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:28.675662Z","iopub.status.busy":"2022-05-26T09:33:28.675096Z","iopub.status.idle":"2022-05-26T09:33:28.683305Z","shell.execute_reply":"2022-05-26T09:33:28.682164Z","shell.execute_reply.started":"2022-05-26T09:33:28.675594Z"},"trusted":true},"outputs":[],"source":["# loss_fn = torch.nn.CrossEntropyLoss()\n","weights = torch.tensor((float(red_ratio), float(green_ratio), float(blue_ratio), black_ratio)).to(device)\n","loss_fn = torch.nn.CrossEntropyLoss(weight=weights)"]},{"cell_type":"markdown","metadata":{},"source":["**TRAINING THE MODEL**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T09:33:28.688204Z","iopub.status.busy":"2022-05-26T09:33:28.687581Z","iopub.status.idle":"2022-05-26T09:33:28.707248Z","shell.execute_reply":"2022-05-26T09:33:28.706165Z","shell.execute_reply.started":"2022-05-26T09:33:28.688162Z"},"trusted":true},"outputs":[],"source":["def train_model():\n","    train_loss = []\n","    model.train()\n","\n","    for image_batch, mask_batch in train_loader:\n","        images = image_batch.to(device)\n","        masks = convert_into_1d(mask_batch.to(device))\n","\n","        output = model(images)\n","                \n","        loss = loss_fn(output if model_type.startswith('Unet') else output['out'], masks.long())\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","\n","        train_loss.append(loss.detach().cpu().numpy())\n","        \n","    return np.mean(train_loss)\n","\n","def validate_model():\n","    val_loss = []\n","    model.eval()\n","    \n","    with torch.no_grad():\n","        for image_batch, mask_batch in val_loader:\n","            images = image_batch.to(device)\n","            masks = convert_into_1d(mask_batch.to(device))\n","\n","            output = model(images)\n","\n","            loss = loss_fn(output if model_type.startswith('Unet') else output['out'], masks.long())\n","            val_loss.append(loss.detach().cpu().numpy())\n","            \n","    return np.mean(val_loss)"]},{"cell_type":"markdown","metadata":{},"source":["# Training cycles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:09:57.479525Z","iopub.status.busy":"2022-05-26T14:09:57.479037Z","iopub.status.idle":"2022-05-26T14:10:28.372377Z","shell.execute_reply":"2022-05-26T14:10:28.370563Z","shell.execute_reply.started":"2022-05-26T14:09:57.479491Z"},"trusted":true},"outputs":[],"source":["previous_val_loss = []\n","mean_of_last_three_val_loss = 10000 # a big number for the beginning (before first 5 values will be initialized)\n","\n","for epoch in range(num_epochs):\n","    train_loss = train_model()\n","    val_loss = validate_model()\n","    \n","    if len(previous_val_loss) >= 5: mean_of_last_three_val_loss = np.mean([previous_val_loss[i] for i in range(-5, 0)])\n","        \n","    if mean_of_last_three_val_loss < val_loss: print(CSTART)\n","    print('EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs, train_loss, val_loss) + CEND)\n","    previous_val_loss.append(val_loss)\n","    \n","    if model_type.startswith('Unet'):\n","        if (epoch+1)%20 == 0:\n","            display_data(data_val, model)\n","            torch.save(model.state_dict(), str(epoch + 1) + '_epoch_' + size_of_the_dataset + '_images.pth')\n","    else:\n","        if (epoch+1)%3 == 0:\n","            display_data(data_val, model)\n","            torch.save(model.state_dict(), str(epoch + 1) + '_epoch_' + size_of_the_dataset + '_images.pth')\n","    \n","    wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:12:38.367236Z","iopub.status.busy":"2022-05-26T14:12:38.366974Z","iopub.status.idle":"2022-05-26T14:12:47.336721Z","shell.execute_reply":"2022-05-26T14:12:47.335972Z","shell.execute_reply.started":"2022-05-26T14:12:38.367209Z"},"trusted":true},"outputs":[],"source":["display_data(data_test, model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
